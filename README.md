## Deep Learning Compiler Study
This is a repository of the study "DL Compiler". The goal of this study is to understand the acceleration of nerual networks with DL Compiler. The topic of acceleration includes `On-Device AI`,`DL Compiler`, `TVM`, `ONNX` , `Compiler` and `PIM`. Our materials are open to this github and youtube. This study is supported by [NOTA](https://nota.ai). Thank you NOTA !


## Paper List (10)
|Paper Name|Conference/Jounr Name|Year|Keyword|
|---|---|---|---|
|Learning to Optimize Tensor Programs|NIPS|2018|Scheduling|
|내용 5|내용 6|내용 7|내용 8|
|내용 9|내용 10|내용 11|내용 12|
   
## Presentation with Video
### Week1: Introduction of Neural network acceleration (February 02, 2020)
**Optimal DNN Primitive Selection with Partitioned Boolean quadratic Programming**  

	Presenter: Constant Park (http://esoc.hanyang.ac.kr/people/sangsoo_park/index.html)  
	PPT: https://github.com/ConstantPark/Nerual-Network-Acceleration/blob/master/Optimal%20DNN%20Primitive%20Selection%20with%20Partitioned%20Boolean%20Quadratic%20Programming.pdf   
	Video: https://youtu.be/ZLGLogU5mt0   


	
## Contributors
**Main Contributor**: Constant Park (sonicstage12@naver.com)  
**Presenters**: Constanr Park (sonicstage12@naver.com), 이제민 (leejaymin@cnu.ac.kr), 김태완 (rlaxodhksk@snu.ac.kr), DownyK (TeamBehindDowny@gmail.com), 전지혜 (jyeah05@gmail.com), Martin (dhhwang89@gmail.com), 김용우 (guruzoa@gmail.com), 
(rlatjrwnd242@naver.com)

